version: '3.5'


# The services are listed in this order
# DataBases
# Kafka
# Spark
# Python

services:

  # DATABASES

  stock-input-mongo:
    image: mongo
    container_name: stock-input-mongo
    expose:
      - 27017
    ports:
      - "127.0.0.1:27017:27017"
    environment:
      - MONGO_INITDB_DATABASE=twitter_sources
    env_file:
      - ./env_files/.env-mongo-input
    volumes:
      - mongo_input_volume:/data/db
    networks:
      - input_network
    restart: unless-stopped

  stock-output-mongo:
    image: mongo
    container_name: stock-output-mongo
    expose:
      - 27017
    ports:
      - "127.0.0.1:27018:27017"
    environment:
      - MONGO_INITDB_DATABASE=text_databases
    env_file:
      - ./env_files/.env-mongo-output
    volumes:
      - mongo_output_volume:/data/db
    networks:
      - input_network
      - output_network
    restart: unless-stopped

  stock-input-postgres:
    image: debezium/postgres:11
    container_name: stock-input-postgres
    expose:
      - 5432
    ports:
      - "127.0.0.1:5432:5432"
    environment:
      - PGDATA=/data/postgres
      - POSTGRES_DB=stocks
    env_file:
      - ./env_files/.env-postgres-input
    volumes:
      - postgres_stock_input:/data/postgres
      - ./misc/create_schema_postgres_input.sql:/docker-entrypoint-initdb.d/create_schema_postgres_input.sql
    networks:
      - input_network
    restart: unless-stopped

  stock-output-postgres:
    image: debezium/postgres:11
    container_name: stock-output-postgres
    expose:
      - 5432
    ports:
      - "127.0.0.1:5433:5432"
    environment:
      - POSTGRES_DB=stocks
      - PGDATA=/data/postgres
    env_file:
      - ./env_files/.env-postgres-output
    volumes:
      - postgres_stock_output:/data/postgres
      - ./misc/create_schema_postgres_output.sql:/docker-entrypoint-initdb.d/create_schema_postgres_output.sql
    networks:
      - input_network
      - output_network
    restart: unless-stopped

  # KAFKA SERVICES

  stock-zookeeper:
    image: confluentinc/cp-zookeeper:5.1.2
    user: root
    container_name: stock-zookeeper
    expose:
      - 2181
    environment:
      - ALLOW_ANONYMOUS_LOGIN=yes
    networks:
      - input_network
      - output_network

  stock-kafka:
    image: confluentinc/cp-kafka:5.1.2
    user: root
    container_name: stock-kafka
    expose:
      - 9092
    environment:
      - KAFKA_BROKER_ID=1
      - KAFKA_LISTENERS=PLAINTEXT://:9092
      - KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://127.0.0.1:9092
      - KAFKA_ZOOKEEPER_CONNECT=stock-zookeeper:2181
      - ALLOW_PLAINTEXT_LISTENER=yes
    depends_on:
      - stock-input-mongo
      - stock-input-postgres
      - stock-output-mongo
      - stock-output-postgres
      - stock-zookeeper
    networks:
      - input_network
      - output_network

    stock-schema-registry:
      image: confluentinc/cp-schema-registry:5.1.2
      container_name: stock-schema-registry
      hostname: schema-registry
      ports:
        - 8081:8081
      depends_on:
        - stock-zookeeper
        - stock-kafka
      environment:
        SCHEMA_REGISTRY_KAFKASTORE_BOOTSTRAP_SERVERS: PLAINTEXT://kafka:9092
        SCHEMA_REGISTRY_HOST_NAME: schema-registry
        SCHEMA_REGISTRY_KAFKASTORE_CONNECTION_URL: zookeeper:2181
        SCHEMA_REGISTRY_LISTENERS: http://0.0.0.0:8081

    stock-ksql-server:
      image: confluentinc/cp-ksql-server:5.1.2
      container_name: stock-ksql-server
      depends_on:
        - stock-kafka
        - stock-schema-registry
      environment:
        KSQL_BOOTSTRAP_SERVERS: kafka:9092
        KSQL_LISTENERS: http://0.0.0.0:8088
        KSQL_KSQL_SCHEMA_REGISTRY_URL: http://schema-registry:8081
        KSQL_KSQL_SERVICE_ID: ksql-server

    stock-connect:
      image: mtpatter/debezium-connect  # built from debezium/connect:0.10
      container_name: stock-connect
      depends_on:
        - stock-zookeeper
        - stock-kafka
        - stock-input-postgres
        - stock-output-postgres
      ports:
        - 8083:8083
      environment:
        GROUP_ID: 1
        CONFIG_STORAGE_TOPIC: my-connect-configs
        OFFSET_STORAGE_TOPIC: my-connect-offsets
        ADVERTISED_HOST_NAME: connect
        BOOTSTRAP_SERVERS: kafka:9092
        CONNECT_INTERNAL_KEY_CONVERTER: org.apache.kafka.connect.json.JsonConverter
        CONNECT_INTERNAL_VALUE_CONVERTER: org.apache.kafka.connect.json.JsonConverte

  # SPARK SERVICES

  stock-spark-master:
    image: docker.io/bitnami/spark:3-debian-10
    container_name: stock-spark-master
    environment:
      - SPARK_MODE=master
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    networks:
      - output_network
    expose:
      - 8080
      - 7077

  stock-spark-worker:
    image: docker.io/bitnami/spark:3-debian-10
    environment:
      - SPARK_MODE=worker
      - SPARK_MASTER_URL=spark://stock-spark-master:7077
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=1
      - SPARK_RPC_AUTHENTICATION_ENABLED=no
      - SPARK_RPC_ENCRYPTION_ENABLED=no
      - SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED=no
      - SPARK_SSL_ENABLED=no
    depends_on:
      - stock-spark-master
    networks:
      - output_network

  spark-client:
    image: docker.io/bitnami/spark:3-debian-10
    entrypoint:
      - sleep
      - infinity
    depends_on:
      - stock-spark-master
      - stock-spark-worker
    networks:
      - output_network

  # PYTHON SERVICES

  stock-python-analysis:
    image: stock-python-analysis
    build:
      context: ./python
      dockerfile: ./dockerfiles/analyzer.Dockerfile
    container_name: stock-python-analysis
    networks:
      - output_network

  stock-input-generator:
    image: stock-input-generator
    build:
      context: ./python
      dockerfile: ./dockerfiles/generator.Dockerfile
    container_name: stock-input-generator
    environment:
      - POSTGRES_INPUT_DB=stocks
      - POSTGRES_INPUT_PORT=5432
      - POSTGRES_INPUT_HOST=stock-input-postgres
    networks:
      - input_network
    command:
      - python -m ./src/generator/__main__.py


networks:
  input_network:
    name: "Input Network"
  output_network:
    name: "Output Network"

volumes:
  mongo_input_volume:
  mongo_output_volume:
  postgres_stock_input:
  postgres_stock_output:
